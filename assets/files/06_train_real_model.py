import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from scipy.stats import pearsonr
import os

# ==========================================
# 1. é…ç½®ä¸è¶…å‚æ•°
# ==========================================
DATA_PATH = "../data/processed/final_dataset.csv"
BATCH_SIZE = 32
LEARNING_RATE = 0.001
EPOCHS = 100
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

print(f"æ­£åœ¨ä½¿ç”¨è®¡ç®—è®¾å¤‡: {DEVICE}")


# ==========================================
# 2. å®šä¹‰æ¨¡å‹æ¶æ„ (åŒä¹‹å‰è®¾è®¡)
# ==========================================
class NRF2PromoterCNN(nn.Module):
    def __init__(self):
        super(NRF2PromoterCNN, self).__init__()
        # è¾“å…¥: 4é€šé“ (ACGT)
        self.conv1 = nn.Conv1d(4, 32, kernel_size=10)
        self.pool1 = nn.MaxPool1d(4, stride=4)
        self.conv2 = nn.Conv1d(32, 64, kernel_size=5)
        self.pool2 = nn.MaxPool1d(4, stride=4)
        self.flatten_dim = 64 * 123
        self.fc1 = nn.Linear(self.flatten_dim, 128)

    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = self.pool1(x)
        x = torch.relu(self.conv2(x))
        x = self.pool2(x)
        x = x.view(x.size(0), -1)
        feature = torch.relu(self.fc1(x))
        return feature


class PathwayMLP(nn.Module):
    def __init__(self):
        super(PathwayMLP, self).__init__()
        # è¾“å…¥: 3ä¸ªåŸºå› çš„è¡¨è¾¾é‡
        self.fc1 = nn.Linear(3, 16)
        self.fc2 = nn.Linear(16, 8)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        return x


class FerroptosisDrugModel(nn.Module):
    def __init__(self):
        super(FerroptosisDrugModel, self).__init__()
        self.cnn = NRF2PromoterCNN()
        self.mlp = PathwayMLP()
        self.fusion_fc1 = nn.Linear(128 + 8, 64)
        self.fusion_fc2 = nn.Linear(64, 1)

    def forward(self, seq, expr):
        cnn_out = self.cnn(seq)
        mlp_out = self.mlp(expr)
        combined = torch.cat((cnn_out, mlp_out), dim=1)
        x = torch.relu(self.fusion_fc1(combined))
        out = self.fusion_fc2(x)
        return out


# ==========================================
# 3. æ•°æ®é›†åŠ è½½å™¨ (Custom Dataset)
# ==========================================
class GDSCDataset(Dataset):
    def __init__(self, csv_file, is_train=True):
        # è¯»å–æ¸…æ´—åçš„ CSV
        self.data = pd.read_csv(csv_file)

        # å½’ä¸€åŒ–è¡¨è¾¾é‡ (Z-score normalization)
        # è¿™ä¸€æ­¥å¯¹æ·±åº¦å­¦ä¹ éå¸¸é‡è¦ï¼Œé˜²æ­¢æ•°å€¼è¿‡å¤§å¯¼è‡´æ¢¯åº¦çˆ†ç‚¸
        feat_cols = ['SLC7A11', 'NQO1', 'NFE2L2']
        self.expr_data = self.data[feat_cols].values
        self.expr_data = (self.expr_data - self.expr_data.mean(axis=0)) / self.expr_data.std(axis=0)

        # è¯»å–æ ‡ç­¾
        # æ‰¾åˆ°åŒ…å« 'IC50' å­—çœ¼çš„åˆ—
        ic50_col = [c for c in self.data.columns if 'IC50' in c][0]
        self.labels = self.data[ic50_col].values

        # --- åºåˆ—æ•°æ®å‡†å¤‡ ---
        # æ—¢ç„¶æˆ‘ä»¬ç”¨çš„æ˜¯"å‚è€ƒåŸºå› ç»„"ï¼Œæ‰€æœ‰æ ·æœ¬å¯¹åº”çš„åŸºå› åºåˆ—å…¶å®æ˜¯ä¸€æ ·çš„
        # æˆ‘ä»¬åœ¨è¿™é‡Œç”Ÿæˆä¸€ä¸ªå›ºå®šçš„ SLC7A11 å¯åŠ¨å­å¼ é‡ä¾› CNN ä½¿ç”¨
        # (åœ¨æ›´å¤æ‚çš„æ¨¡å‹ä¸­ï¼Œè¿™é‡Œä¼šæ ¹æ® mutation è¯»å–ä¸åŒçš„åºåˆ—)
        print("æ­£åœ¨ç”ŸæˆåŸºå› ç»„åºåˆ—å¼ é‡...")
        # æ¨¡æ‹Ÿç”Ÿæˆä¸€ä¸ª One-hot çŸ©é˜µ (4, 2000)
        # çœŸå®åœºæ™¯ä¸­ï¼Œè¿™é‡Œåº”è¯¥åŠ è½½ step 01 ç”Ÿæˆçš„ .pt æ–‡ä»¶
        self.seq_tensor = torch.randn(4, 2000)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        # 1. è¡¨è¾¾é‡æ•°æ®
        expr = torch.tensor(self.expr_data[idx], dtype=torch.float32)

        # 2. åºåˆ—æ•°æ® (æ‰€æœ‰æ ·æœ¬å…±äº«åŒä¸€ä¸ªå‚è€ƒåºåˆ—ï¼Œä½œä¸º Context)
        seq = self.seq_tensor.clone().detach().float()

        # 3. æ ‡ç­¾ (IC50)
        label = torch.tensor(self.labels[idx], dtype=torch.float32)

        return seq, expr, label


# ==========================================
# 4. è®­ç»ƒä¸è¯„ä¼°æµç¨‹
# ==========================================
def train_model():
    # A. å‡†å¤‡æ•°æ®
    print(f"æ­£åœ¨åŠ è½½æ•°æ®é›†: {DATA_PATH}")
    full_dataset = GDSCDataset(DATA_PATH)

    # æ‹†åˆ†è®­ç»ƒé›† (80%) å’Œ æµ‹è¯•é›† (20%)
    train_size = int(0.8 * len(full_dataset))
    test_size = len(full_dataset) - train_size
    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)

    print(f"è®­ç»ƒé›†æ ·æœ¬: {len(train_dataset)}, æµ‹è¯•é›†æ ·æœ¬: {len(test_dataset)}")

    # B. åˆå§‹åŒ–
    model = FerroptosisDrugModel().to(DEVICE)
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
    criterion = nn.MSELoss()  # å›å½’é—®é¢˜ç”¨å‡æ–¹è¯¯å·®

    # C. è®­ç»ƒå¾ªç¯
    print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    best_corr = -1.0  # è®°å½•æœ€å¥½çš„ç›¸å…³ç³»æ•°

    for epoch in range(EPOCHS):
        model.train()
        train_loss = 0.0

        for seq, expr, label in train_loader:
            seq, expr, label = seq.to(DEVICE), expr.to(DEVICE), label.to(DEVICE)

            optimizer.zero_grad()
            output = model(seq, expr)
            loss = criterion(output.squeeze(), label)  # squeezeæŠŠ [32,1] å˜æˆ [32]
            loss.backward()
            optimizer.step()

            train_loss += loss.item()

        # D. æ¯ä¸ª Epoch ç»“æŸåè¿›è¡Œæµ‹è¯•
        model.eval()
        all_preds = []
        all_labels = []

        with torch.no_grad():
            for seq, expr, label in test_loader:
                seq, expr, label = seq.to(DEVICE), expr.to(DEVICE), label.to(DEVICE)
                output = model(seq, expr)
                all_preds.extend(output.squeeze().cpu().numpy())
                all_labels.extend(label.cpu().numpy())

        # è®¡ç®—ç”Ÿä¿¡æ ¸å¿ƒæŒ‡æ ‡ï¼šçš®å°”é€Šç›¸å…³ç³»æ•° (Pearson R)
        # R è¶Šæ¥è¿‘ 1ï¼Œè¯´æ˜é¢„æµ‹è¶Šå‡†
        pearson_r, _ = pearsonr(all_labels, all_preds)

        if (epoch + 1) % 10 == 0:
            print(
                f"Epoch [{epoch + 1}/{EPOCHS}] | Loss: {train_loss / len(train_loader):.4f} | Test Pearson R: {pearson_r:.4f}")

            # å¦‚æœæ¨¡å‹è¿›æ­¥äº†ï¼Œä¿å­˜ä¸€ä¸‹
            if pearson_r > best_corr:
                best_corr = pearson_r
                torch.save(model.state_dict(), "../models/best_model.pth")

    print(f"\nğŸ† è®­ç»ƒç»“æŸ! æœ€ä½³æµ‹è¯•é›†ç›¸å…³ç³»æ•° (R): {best_corr:.4f}")
    print("æ¨¡å‹å·²ä¿å­˜è‡³ ../models/best_model.pth")


if __name__ == "__main__":
    if os.path.exists(DATA_PATH):
        train_model()
    else:
        print(f"âŒ æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶: {DATA_PATH}ï¼Œè¯·å…ˆè¿è¡Œ 05_real_data_prep.py")